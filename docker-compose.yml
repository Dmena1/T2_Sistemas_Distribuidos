version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "22181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      - zookeeper
    ports:
      - "29092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: ds_user
      POSTGRES_PASSWORD: ds_pass
      POSTGRES_DB: ds_db
    volumes:
      - ./sql:/docker-entrypoint-initdb.d
    ports:
      - "55432:5432"

  kafka-wait:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      - kafka
    command: bash -c "echo 'Waiting for Kafka to be ready...'; sleep 30; echo 'Kafka should be ready now'"
    profiles: [ "wait" ]

  llm-worker:
    build: ./services
    container_name: llm_worker
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - PYTHONUNBUFFERED=1
    volumes:
      - ./services:/app
    command: bash -c "echo 'LLM Worker waiting for Kafka...'; sleep 35; echo 'Starting LLM Worker'; python llm_worker.py"

  retry-worker:
    build: ./services
    container_name: retry_worker
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - MAX_ATTEMPTS=5
      - PYTHONUNBUFFERED=1
    volumes:
      - ./services:/app
    command: bash -c "echo 'Retry Worker waiting for Kafka...'; sleep 40; echo 'Starting Retry Worker'; python retry_worker.py"

  storage-consumer:
    build: ./services
    container_name: storage_consumer
    depends_on:
      - kafka
      - postgres
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=ds_db
      - POSTGRES_USER=ds_user
      - POSTGRES_PASSWORD=ds_pass
      - PYTHONUNBUFFERED=1
    volumes:
      - ./services:/app
    command: bash -c "echo 'Storage Consumer waiting for services...'; sleep 45; echo 'Starting Storage Consumer'; python storage_consumer.py"

  query-gateway:
    build: ./services
    container_name: query_gateway
    depends_on:
      - kafka
      - postgres
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=ds_db
      - POSTGRES_USER=ds_user
      - POSTGRES_PASSWORD=ds_pass
      - PYTHONUNBUFFERED=1
    volumes:
      - ./services:/app
    command: bash -c "echo 'Query Gateway waiting for services...'; sleep 40; echo 'Starting Query Gateway'; python query_gateway.py"

  flink-simulator:
    build: ./services
    container_name: flink_simulator
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - SCORE_UMBRAL=0.3
      - MAX_RETRIES=3
      - PYTHONUNBUFFERED=1
    volumes:
      - ./services:/app
    command: bash -c "echo 'Flink Simulator waiting for Kafka...'; sleep 50; echo 'Starting Flink Simulator'; python flink_simulator.py"

  traffic-generator:
    build: ./services
    container_name: traffic_generator
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - PYTHONUNBUFFERED=1
    volumes:
      - ./services:/app
    command: bash -c "echo 'Traffic Generator waiting for Kafka...'; sleep 55; echo 'Starting Traffic Generator'; python traffic_generator.py"

  # Flink real (opcional): levantar clúster para ejecutar pyflink
  flink-jobmanager:
    image: flink:1.17.2-scala_2.12
    container_name: flink_jobmanager
    ports:
      - "8081:8081"
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    command: jobmanager
    volumes:
      - ./flink-jars:/opt/flink/lib
    depends_on:
      - kafka

  flink-taskmanager:
    image: flink:1.17.2-scala_2.12
    container_name: flink_taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    command: taskmanager
    volumes:
      - ./flink-jars:/opt/flink/lib
    depends_on:
      - flink-jobmanager

  # ============================================
  # TAREA 3: SERVICIOS DE ANÁLISIS BATCH
  # ============================================

  hadoop-namenode:
    build: ./batch_analysis/hadoop
    container_name: hadoop_namenode
    hostname: hadoop-namenode
    ports:
      - "9870:9870" # HDFS Web UI
      - "9000:9000" # HDFS port
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./batch_analysis/data:/data
      - ./batch_analysis/pig:/pig_scripts
      - ./batch_analysis/results:/results
    environment:
      - CLUSTER_NAME=hadoop-cluster
    command: bash -c "/opt/init-hdfs.sh"

  hadoop-datanode:
    build: ./batch_analysis/hadoop
    container_name: hadoop_datanode
    hostname: hadoop-datanode
    depends_on:
      - hadoop-namenode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      - CLUSTER_NAME=hadoop-cluster
    command: bash -c "sleep 20 && hdfs datanode"

  batch-extractor:
    build: ./batch_analysis
    container_name: batch_extractor
    depends_on:
      - postgres
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=ds_db
      - POSTGRES_USER=ds_user
      - POSTGRES_PASSWORD=ds_pass
    volumes:
      - ./batch_analysis:/app
      - ./batch_analysis/data:/data
    profiles: [ "batch" ] # Solo se ejecuta cuando se especifica el perfil

volumes:
  hadoop_namenode:
  hadoop_datanode:
